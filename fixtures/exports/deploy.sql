-- Compiled Fixture: exports
-- Generated: 2025-11-25T23:20:54.788Z
-- Parameters: :database, :schema
--
-- Usage:
--   Replace :database and :schema placeholders before execution
--   Example: sed 's/:database/db_main/g; s/:schema/ns_tenant_abc123/g' deploy.sql | psql

BEGIN;

-- Create schema if not exists
CREATE SCHEMA IF NOT EXISTS :schema;

-- Set search path to target schema
SET search_path TO :schema, public;

-- ============================================================================
-- Monk API - Exports Fixture Loader
-- ============================================================================
-- Provides data export pipeline functionality
--
-- Dependencies: system
-- Models: extracts, extract_runs, extract_artifacts

-- ECHO: '========================================'
-- ECHO: 'Loading Exports Fixture'
-- ECHO: '========================================'

-- TABLE DEFINITIONS
-- ECHO: ''
-- ECHO: 'Table Definitions'
-- BEGIN: describe/extracts.sql
-- ============================================================================
-- MODEL: extracts
-- ============================================================================
-- Data extraction job configurations

CREATE TABLE "extracts" (
    -- System fields
	"id" uuid PRIMARY KEY DEFAULT gen_random_uuid() NOT NULL,
	"access_read" uuid[] DEFAULT '{}'::uuid[],
	"access_edit" uuid[] DEFAULT '{}'::uuid[],
	"access_full" uuid[] DEFAULT '{}'::uuid[],
	"access_deny" uuid[] DEFAULT '{}'::uuid[],
	"created_at" timestamp DEFAULT now() NOT NULL,
	"updated_at" timestamp DEFAULT now() NOT NULL,
	"trashed_at" timestamp,
	"deleted_at" timestamp,

	-- Extract configuration
	"name" text NOT NULL,
	"description" text,
	"format" text DEFAULT 'jsonl' NOT NULL CHECK ("format" IN ('yaml', 'json', 'jsonl', 'archive')),
	"include" text[] DEFAULT ARRAY['describe', 'data']::text[],
	"models" text[],
	"filter" jsonb,
	"compress" boolean DEFAULT true,
	"split_files" boolean DEFAULT false,

	-- Scheduling
	"schedule" text,
	"schedule_enabled" boolean DEFAULT false,
	"retention_days" integer DEFAULT 7,
	"enabled" boolean DEFAULT true,

	-- Stats (denormalized)
	"last_run_id" uuid,
	"last_run_status" text,
	"last_run_at" timestamp,
	"total_runs" integer DEFAULT 0,
	"successful_runs" integer DEFAULT 0,
	"failed_runs" integer DEFAULT 0
);

CREATE INDEX "idx_extracts_enabled" ON "extracts" ("enabled");
CREATE INDEX "idx_extracts_schedule_enabled" ON "extracts" ("schedule_enabled") WHERE "schedule_enabled" = true;

-- END: describe/extracts.sql
-- BEGIN: describe/extract_runs.sql
-- ============================================================================
-- MODEL: extract_runs
-- ============================================================================
-- Individual execution runs of extract jobs

CREATE TABLE "extract_runs" (
    -- System fields
	"id" uuid PRIMARY KEY DEFAULT gen_random_uuid() NOT NULL,
	"access_read" uuid[] DEFAULT '{}'::uuid[],
	"access_edit" uuid[] DEFAULT '{}'::uuid[],
	"access_full" uuid[] DEFAULT '{}'::uuid[],
	"access_deny" uuid[] DEFAULT '{}'::uuid[],
	"created_at" timestamp DEFAULT now() NOT NULL,
	"updated_at" timestamp DEFAULT now() NOT NULL,
	"trashed_at" timestamp,
	"deleted_at" timestamp,

	-- Relationship
	"extract_id" uuid NOT NULL,
	"extract_name" text,

	-- Execution state
	"status" text DEFAULT 'pending' NOT NULL CHECK ("status" IN ('pending', 'queued', 'running', 'completed', 'failed', 'cancelled')),
	"progress" integer DEFAULT 0 CHECK ("progress" BETWEEN 0 AND 100),
	"progress_detail" jsonb,

	-- Timing
	"started_at" timestamp,
	"completed_at" timestamp,
	"duration_seconds" integer,

	-- Results
	"records_exported" integer DEFAULT 0,
	"models_exported" integer DEFAULT 0,
	"artifacts_created" integer DEFAULT 0,
	"total_size_bytes" bigint DEFAULT 0,

	-- Error handling
	"error" text,
	"error_detail" jsonb,

	-- Execution context
	"executed_by" uuid,
	"triggered_by" text DEFAULT 'manual' CHECK ("triggered_by" IN ('manual', 'schedule', 'api')),
	"config_snapshot" jsonb
);

-- Foreign key
ALTER TABLE "extract_runs" ADD CONSTRAINT "extract_runs_extract_id_fk"
    FOREIGN KEY ("extract_id") REFERENCES "extracts"("id")
    ON DELETE CASCADE;

-- Indexes
CREATE INDEX "idx_extract_runs_extract_id" ON "extract_runs" ("extract_id");
CREATE INDEX "idx_extract_runs_status" ON "extract_runs" ("status");
CREATE INDEX "idx_extract_runs_created_at" ON "extract_runs" ("created_at" DESC);

-- END: describe/extract_runs.sql
-- BEGIN: describe/extract_artifacts.sql
-- ============================================================================
-- MODEL: extract_artifacts
-- ============================================================================
-- Individual downloadable files generated by extract runs

CREATE TABLE "extract_artifacts" (
    -- System fields
	"id" uuid PRIMARY KEY DEFAULT gen_random_uuid() NOT NULL,
	"access_read" uuid[] DEFAULT '{}'::uuid[],
	"access_edit" uuid[] DEFAULT '{}'::uuid[],
	"access_full" uuid[] DEFAULT '{}'::uuid[],
	"access_deny" uuid[] DEFAULT '{}'::uuid[],
	"created_at" timestamp DEFAULT now() NOT NULL,
	"updated_at" timestamp DEFAULT now() NOT NULL,
	"trashed_at" timestamp,
	"deleted_at" timestamp,

	-- Relationships
	"run_id" uuid NOT NULL,
	"extract_id" uuid NOT NULL,

	-- Artifact identity
	"artifact_type" text NOT NULL,
	"artifact_name" text NOT NULL,

	-- Storage
	"storage_path" text NOT NULL,
	"storage_backend" text DEFAULT 'local' CHECK ("storage_backend" IN ('local', 's3', 'gcs', 'azure')),
	"download_url" text,

	-- Metadata
	"format" text,
	"size_bytes" bigint NOT NULL,
	"checksum" text,
	"content_type" text DEFAULT 'application/octet-stream',

	-- Lifecycle
	"expires_at" timestamp,
	"accessed_at" timestamp,
	"download_count" integer DEFAULT 0,

	-- Flags
	"is_primary" boolean DEFAULT false
);

-- Foreign keys
ALTER TABLE "extract_artifacts" ADD CONSTRAINT "extract_artifacts_run_id_fk"
    FOREIGN KEY ("run_id") REFERENCES "extract_runs"("id")
    ON DELETE CASCADE;

-- Indexes
CREATE INDEX "idx_extract_artifacts_run_id" ON "extract_artifacts" ("run_id");
CREATE INDEX "idx_extract_artifacts_extract_id" ON "extract_artifacts" ("extract_id");
CREATE INDEX "idx_extract_artifacts_expires_at" ON "extract_artifacts" ("expires_at") WHERE "expires_at" IS NOT NULL;

-- END: describe/extract_artifacts.sql

-- DATA
-- ECHO: ''
-- ECHO: 'Data Inserts'
-- BEGIN: data/extracts.sql
-- ============================================================================
-- DATA: Register extract models and define fields
-- ============================================================================

-- Register extracts model
INSERT INTO "models" (model_name, status, sudo, description)
VALUES (
    'extracts',
    'system',
    false,
    'Data extraction job configurations'
);

-- Register extract_runs model
INSERT INTO "models" (model_name, status, sudo, description)
VALUES (
    'extract_runs',
    'system',
    false,
    'Individual execution runs of extract jobs'
);

-- Register extract_artifacts model
INSERT INTO "models" (model_name, status, sudo, description)
VALUES (
    'extract_artifacts',
    'system',
    false,
    'Downloadable files generated by extract runs'
);

-- ============================================================================
-- FIELDS FOR: extracts
-- ============================================================================
INSERT INTO "fields" (model_name, field_name, type, required, description) VALUES
    ('extracts', 'name', 'text', true, 'Human-readable name for this extract'),
    ('extracts', 'description', 'text', false, 'Purpose and notes'),
    ('extracts', 'format', 'text', false, 'Output format: yaml, json, jsonl, archive'),
    ('extracts', 'include', 'text[]', false, 'What to include: describe, data, acls, files'),
    ('extracts', 'models', 'text[]', false, 'Specific models to extract (null = all)'),
    ('extracts', 'filter', 'jsonb', false, 'Optional filter to apply per model'),
    ('extracts', 'compress', 'boolean', false, 'Gzip the output'),
    ('extracts', 'split_files', 'boolean', false, 'Create separate file per model'),
    ('extracts', 'schedule', 'text', false, 'Cron expression'),
    ('extracts', 'schedule_enabled', 'boolean', false, 'Enable scheduled execution'),
    ('extracts', 'retention_days', 'integer', false, 'How long to keep artifacts'),
    ('extracts', 'enabled', 'boolean', false, 'Can this extract be executed'),
    ('extracts', 'last_run_id', 'uuid', false, 'Most recent execution'),
    ('extracts', 'last_run_status', 'text', false, 'Status of last run'),
    ('extracts', 'last_run_at', 'timestamp', false, 'When last executed'),
    ('extracts', 'total_runs', 'integer', false, 'Total execution count'),
    ('extracts', 'successful_runs', 'integer', false, 'Successful execution count'),
    ('extracts', 'failed_runs', 'integer', false, 'Failed execution count');

-- ============================================================================
-- FIELDS FOR: extract_runs
-- ============================================================================
INSERT INTO "fields" (model_name, field_name, type, required, description) VALUES
    ('extract_runs', 'extract_id', 'uuid', true, 'Foreign key to extracts table'),
    ('extract_runs', 'extract_name', 'text', false, 'Denormalized for easier queries'),
    ('extract_runs', 'status', 'text', true, 'Execution status: pending, queued, running, completed, failed, cancelled'),
    ('extract_runs', 'progress', 'integer', false, 'Completion percentage (0-100)'),
    ('extract_runs', 'progress_detail', 'jsonb', false, 'Detailed progress information'),
    ('extract_runs', 'started_at', 'timestamp', false, 'When execution began'),
    ('extract_runs', 'completed_at', 'timestamp', false, 'When execution finished'),
    ('extract_runs', 'duration_seconds', 'integer', false, 'Execution time in seconds'),
    ('extract_runs', 'records_exported', 'integer', false, 'Total records exported'),
    ('extract_runs', 'models_exported', 'integer', false, 'Number of models exported'),
    ('extract_runs', 'artifacts_created', 'integer', false, 'Number of artifacts generated'),
    ('extract_runs', 'total_size_bytes', 'bigint', false, 'Total size of all artifacts'),
    ('extract_runs', 'error', 'text', false, 'Error message if failed'),
    ('extract_runs', 'error_detail', 'jsonb', false, 'Detailed error context'),
    ('extract_runs', 'executed_by', 'uuid', false, 'User who triggered execution'),
    ('extract_runs', 'triggered_by', 'text', false, 'How it was triggered: manual, schedule, api'),
    ('extract_runs', 'config_snapshot', 'jsonb', false, 'Copy of extract config at execution time');

-- ============================================================================
-- FIELDS FOR: extract_artifacts
-- ============================================================================
INSERT INTO "fields" (model_name, field_name, type, required, description) VALUES
    ('extract_artifacts', 'run_id', 'uuid', true, 'Foreign key to extract_runs table'),
    ('extract_artifacts', 'extract_id', 'uuid', true, 'Denormalized for cleanup queries'),
    ('extract_artifacts', 'artifact_type', 'text', true, 'Type: describe, data-{model}, manifest'),
    ('extract_artifacts', 'artifact_name', 'text', true, 'Filename'),
    ('extract_artifacts', 'storage_path', 'text', true, 'Local path or cloud key'),
    ('extract_artifacts', 'storage_backend', 'text', false, 'Storage backend: local, s3, gcs, azure'),
    ('extract_artifacts', 'download_url', 'text', false, 'Public or signed URL for download'),
    ('extract_artifacts', 'format', 'text', false, 'File format: jsonl, yaml, json, tar.gz'),
    ('extract_artifacts', 'size_bytes', 'bigint', true, 'File size in bytes'),
    ('extract_artifacts', 'checksum', 'text', false, 'SHA256 hash for integrity'),
    ('extract_artifacts', 'content_type', 'text', false, 'MIME type'),
    ('extract_artifacts', 'expires_at', 'timestamp', false, 'When this artifact will be deleted'),
    ('extract_artifacts', 'accessed_at', 'timestamp', false, 'Last download time'),
    ('extract_artifacts', 'download_count', 'integer', false, 'Number of downloads'),
    ('extract_artifacts', 'is_primary', 'boolean', false, 'Primary downloadable artifact');

-- END: data/extracts.sql

-- ECHO: ''
-- ECHO: '========================================'
-- ECHO: 'Exports Fixture Loaded Successfully'
-- ECHO: '========================================'

COMMIT;
